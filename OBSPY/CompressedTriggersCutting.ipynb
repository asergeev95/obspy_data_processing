{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from obspy import read\n",
    "from obspy.core import UTCDateTime\n",
    "from obspy.core.stream import Stream\n",
    "from SeismicData import SeismicData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "root_folder = \"E:\\\\UDINA_2018\\\\miniSEED\"\n",
    "ud01_data_folder_path = root_folder+\"\\\\UD01\"\n",
    "ud02_data_folder_path = root_folder+\"\\\\UD02\"\n",
    "ud03_data_folder_path = root_folder+\"\\\\UD03\"\n",
    "ud04_data_folder_path = root_folder+\"\\\\UD04\"\n",
    "\n",
    "directions_data_folders = [\"6d97e2\", \"6d97n2\", \"6d97z2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def process_station_data(station_data_folder, file_num):\n",
    "    import os \n",
    "    station_data = Stream()\n",
    "    for direction in directions_data_folders:\n",
    "        direction_stream = Stream()\n",
    "        data_folder = station_data_folder+\"\\\\\"+direction\n",
    "        for filename in (os.listdir(data_folder))[file_num:file_num+10]:\n",
    "            input_stream=read(data_folder+\"\\\\\"+filename)\n",
    "            direction_stream += input_stream\n",
    "        direction_stream.merge(fill_value=0)\n",
    "        station_data+=direction_stream\n",
    "    return station_data\n",
    "\n",
    "def square_sum (seismic_data):\n",
    "    square_sum = list()\n",
    "    for i, time in enumerate(seismic_data.times):\n",
    "        summ = np.float64(0)\n",
    "        for trace in seismic_data.traces:\n",
    "            summ+=trace[i]*trace[i]\n",
    "        summ /= seismic_data.alive_traces_count[i]\n",
    "        square_sum.append((time, summ))\n",
    "    return square_sum\n",
    "\n",
    "def union_close_times(times):\n",
    "    united_times = []\n",
    "    for i in range(len(times)):\n",
    "        if ((times[i].datetime - times[i-1].datetime).total_seconds())//60 > 3:\n",
    "            united_times.append(times[i])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    united_times.append(times[len(times)-1])\n",
    "    return united_times\n",
    "def moving_average(a, n):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\obspy\\signal\\detrend.py:31: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(data.dtype, float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station data preprocessing...\n",
      "max trace = .6D97..HHE | 2018-05-06T00:00:00.000000Z - 2018-05-06T09:59:59.990000Z | 100.0 Hz, 3600000 samples\n",
      "max trace times = [UTCDateTime(2018, 5, 6, 0, 0) UTCDateTime(2018, 5, 6, 0, 0, 0, 10000)\n",
      " UTCDateTime(2018, 5, 6, 0, 0, 0, 20000) ...\n",
      " UTCDateTime(2018, 5, 6, 9, 59, 59, 970000)\n",
      " UTCDateTime(2018, 5, 6, 9, 59, 59, 980000)\n",
      " UTCDateTime(2018, 5, 6, 9, 59, 59, 990000)]\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Trace preprocessing...\n",
      "Trace preprocessing finished\n",
      "Calculating number of alive traces...\n",
      "Calculating number of alive traces finished\n",
      "Station data preprocessing finished\n",
      "len peaks = 1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_num = 0\n",
    "while file_num < 1400:\n",
    "    print('file number: {0}'.format(file_num))\n",
    "    station_data = process_station_data(ud01_data_folder_path, file_num)\n",
    "    station_data += process_station_data(ud02_data_folder_path, file_num)\n",
    "    station_data += process_station_data(ud03_data_folder_path, file_num)\n",
    "    station_data += process_station_data(ud04_data_folder_path, file_num)\n",
    "\n",
    "    min_filtering_frequency = 2\n",
    "    max_filtering_frequency = 6\n",
    "    station_data = station_data.detrend()\n",
    "    station_data = station_data.filter(\"bandpass\", freqmin=min_filtering_frequency,freqmax = max_filtering_frequency)\n",
    "    \n",
    "    seismic_data = SeismicData(station_data)\n",
    "    squareSum = square_sum(seismic_data)\n",
    "    x = list()\n",
    "    y = list()\n",
    "\n",
    "    for item in squareSum:\n",
    "        x.append(item[0])\n",
    "        y.append(item[1])\n",
    "\n",
    "    m=2250\n",
    "    x_av = x.copy()\n",
    "    y_av = moving_average(y.copy(), m)\n",
    "    x_av = np.asarray(x_av[:len(y_av)])\n",
    "    \n",
    "    peaks, _ = find_peaks(y_av, height=0.08e6, distance=12000)\n",
    "    print('\\tlen peaks = {0}'.format(len(peaks)))\n",
    "    if len(peaks) > 0 and len(peaks) < 200:\n",
    "        lpeaks = np.asarray(peaks)\n",
    "        xticks = [x.datetime.strftime(\"%Y-%m-%d %H:%M:%S\") for x in  x_av][::120000]\n",
    "        print('\\tx ticks calculated')\n",
    "        plt.figure(figsize=(30,10))\n",
    "        plt.xticks(x_av, xticks, rotation=90)\n",
    "        print('\\tticks plotted')\n",
    "        plt.plot(x_av,y_av)\n",
    "        plt.plot(x_av[lpeaks], y_av[lpeaks], \"x\")\n",
    "        print('\\tplot received')\n",
    "        plt.savefig('plots\\\\plot_peaks_{0}.png'.format(datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")))\n",
    "        print('\\tplot saved')\n",
    "        \n",
    "        times = station_data[0].times(\"utcdatetime\")\n",
    "        peaks_times = times[lpeaks]\n",
    "        filtered_times = union_close_times(peaks_times)\n",
    "        filtered_times.append(peaks_times[len(peaks_times)-1])\n",
    "        print(filtered_times)\n",
    "        \n",
    "        for i in range(len(filtered_times)):\n",
    "            f_time = filtered_times[i]\n",
    "            ind = np.where(times==f_time)[0][0]\n",
    "            startInd = ind - 3000\n",
    "            endInd = ind + 30000\n",
    "            if endInd > len(times):\n",
    "                endInd = len(times) - 1\n",
    "            copy = station_data.copy()\n",
    "            \n",
    "            trimed = copy.trim(starttime=times[startInd], endtime=times[endInd])\n",
    "            trimed.write(\"automatic_triggers_long_20190310\\\\trigger—{0}.msd\".format(str(f_time).replace(\":\", \"\").replace(\"-\", \"\").replace(\".\", \"\")), format=\"MSEED\")\n",
    "            \n",
    "            startInd = ind - 1500\n",
    "            endInd = ind + 3000\n",
    "            if endInd > len(times):\n",
    "                endInd = len(times) - 1\n",
    "            copy = station_data.copy()\n",
    "            trimed = copy.trim(starttime=times[startInd], endtime=times[endInd])\n",
    "            trimed.write(\"automatic_triggers_20190310\\\\trigger—{0}.msd\".format(str(f_time).replace(\":\", \"\").replace(\"-\", \"\").replace(\".\", \"\")), format=\"MSEED\")\n",
    "            \n",
    "        file_num += 10\n",
    "    else:\n",
    "        file_num += 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
